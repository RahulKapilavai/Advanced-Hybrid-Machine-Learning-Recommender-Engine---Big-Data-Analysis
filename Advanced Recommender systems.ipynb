{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing PySpark\n",
        "\n",
        "To initiate our journey with **PySpark** in Google Colab, the first step involves installing the PySpark package. **PySpark** serves as the Python API for **Apache Spark**, standing out as an exceptionally powerful tool tailored for the realms of big data processing and analysis. To carry out the installation, a specific `pip install` command tailored for PySpark will be executed. This action leverages **pip**, the renowned package installer for Python. By incorporating an exclamation mark at the command's outset, we signal Colab to execute shell commands, which are typically run in terminals or command prompts. Upon the successful execution of this installation command, we unlock the ability to harness PySpark's capabilities for big data processing and analysis within our notebook.\n"
      ],
      "metadata": {
        "id": "uj8AkNW13zHu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IZrnQcIE-A3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd6b00a-8a75-44ae-cc8d-92765d568c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=c4e42b8011474a55af8565772c410062f56903d730ef61ee42684c00c34b7b8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading Files in Google Colab\n",
        "To upload files from your local file system to a Colab notebook, we utilize a specific function from the 'google.colab' module.\n",
        "This process involves importing the 'files' class from the 'google.colab' module first.\n",
        "Once imported, we call the 'upload' method on 'files' which initiates the file upload process. A file selector dialog will appear, allowing you to choose which file(s) you wish to upload.\n",
        "After selecting the file(s) and confirming the upload, the uploaded files will be available in the notebook's workspace.\n"
      ],
      "metadata": {
        "id": "wkavq0lL4vGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQ4-GjEw_yWv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "88c9d1b5-dfe9-44f5-9305-4010abc38b0c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4105ba3-4498-4fd5-ac9b-2f93e88d44a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e4105ba3-4498-4fd5-ac9b-2f93e88d44a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving movies_metadata.csv to movies_metadata (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up a Spark Session and Preparing Movie Data in PySpark\n",
        "\n",
        "- Import necessary libraries from PySpark for data manipulation and defining data types.\n",
        "- Initialize a SparkSession with an appropriate application name, such as \"MovieDataAnalysis\".\n",
        "- Define the path to your uploaded CSV file containing movie metadata.\n",
        "- Load the CSV file into a DataFrame, ensuring to treat the first row as headers.\n",
        "- Cast specific columns to their correct data types (e.g., budget and revenue to IntegerType, popularity, and vote_average to FloatType) for accurate data handling.\n",
        "- Fill missing or null values in numeric columns with 0 and string columns with a placeholder text like \"Unknown\" to maintain data consistency.\n",
        "- Convert the 'adult' column to a boolean type based on its string value for clearer data representation.\n",
        "- Finally, display the DataFrame schema and the first few rows to verify the changes and ensure the data is correctly loaded and formatted.\n"
      ],
      "metadata": {
        "id": "Sa85opk75w0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.sql.types import IntegerType, FloatType\n",
        "from pyspark.sql.functions import col, explode, split\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"MovieDataAnalysis\").getOrCreate()\n",
        "\n",
        "# Path to the uploaded CSV file\n",
        "movies_path = \"movies_metadata.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "movies_df = spark.read.option(\"header\", \"true\").csv(movies_path)\n",
        "\n",
        "# Convert budget, revenue to IntegerType, popularity and vote_average to FloatType\n",
        "movies_df = movies_df.withColumn(\"budget\", col(\"budget\").cast(IntegerType())) \\\n",
        "                     .withColumn(\"revenue\", col(\"revenue\").cast(IntegerType())) \\\n",
        "                     .withColumn(\"popularity\", col(\"popularity\").cast(FloatType())) \\\n",
        "                     .withColumn(\"vote_average\", col(\"vote_average\").cast(FloatType())) \\\n",
        "                     .withColumn(\"runtime\", col(\"runtime\").cast(IntegerType()))\n",
        "\n",
        "# Handling missing or null values. For simplicity, we'll fill missing numeric values with 0\n",
        "# and missing string values with \"Unknown\". Adjust this based on your requirements.\n",
        "movies_df = movies_df.fillna({\n",
        "    'budget': 0,\n",
        "    'revenue': 0,\n",
        "    'popularity': 0.0,\n",
        "    'vote_average': 0.0,\n",
        "    'runtime': 0,\n",
        "    'genres': 'Unknown',\n",
        "    'production_companies': 'Unknown',\n",
        "    'production_countries': 'Unknown'\n",
        "})\n",
        "\n",
        "# For boolean columns like 'adult', convert to a true boolean type\n",
        "movies_df = movies_df.withColumn('adult', when(col('adult') == 'True', True).otherwise(False))\n",
        "\n",
        "# Show the DataFrame schema to verify the changes\n",
        "movies_df.printSchema()\n",
        "\n",
        "# Display the first few rows of the DataFrame to check the cleaned data\n",
        "movies_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJiMtU-cuLC",
        "outputId": "d5c85c42-4ce3-4d8d-9d86-7f2461c64168"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- adult: boolean (nullable = false)\n",
            " |-- belongs_to_collection: string (nullable = true)\n",
            " |-- budget: integer (nullable = false)\n",
            " |-- genres: string (nullable = false)\n",
            " |-- homepage: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- imdb_id: string (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: float (nullable = false)\n",
            " |-- poster_path: string (nullable = true)\n",
            " |-- production_companies: string (nullable = false)\n",
            " |-- production_countries: string (nullable = false)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: integer (nullable = false)\n",
            " |-- runtime: integer (nullable = false)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- tagline: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- video: string (nullable = true)\n",
            " |-- vote_average: float (nullable = false)\n",
            " |-- vote_count: string (nullable = true)\n",
            "\n",
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+---------+-------+--------------------+--------+--------------------+--------------------+--------+------------+-----------------+\n",
            "|adult|belongs_to_collection|  budget|              genres|            homepage|   id|  imdb_id|original_language|      original_title|            overview|popularity|         poster_path|production_companies|production_countries|        release_date|  revenue|runtime|    spoken_languages|  status|             tagline|               title|   video|vote_average|       vote_count|\n",
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+---------+-------+--------------------+--------+--------------------+--------------------+--------+------------+-----------------+\n",
            "|false| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|  862|tt0114709|               en|           Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|          1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|                NULL|           Toy Story|   False|         7.7|             5415|\n",
            "|false|                 NULL|65000000|[{'id': 12, 'name...|                NULL| 8844|tt0113497|               en|             Jumanji|When siblings Jud...|  17.01554|/vzmL6fP7aPKNKPRT...|[{'name': 'TriSta...|[{'iso_3166_1': '...|          1995-12-15|262797249|    104|[{'iso_639_1': 'e...|Released|Roll the dice and...|             Jumanji|   False|         6.9|             2413|\n",
            "|false| {'id': 119050, 'n...|       0|[{'id': 10749, 'n...|                NULL|15602|tt0113228|               en|    Grumpier Old Men|A family wedding ...|   11.7129|/6ksm1sjKMFLbO7UY...|[{'name': 'Warner...|[{'iso_3166_1': '...|          1995-12-22|        0|    101|[{'iso_639_1': 'e...|Released|Still Yelling. St...|    Grumpier Old Men|   False|         6.5|               92|\n",
            "|false|                 NULL|16000000|[{'id': 35, 'name...|                NULL|31357|tt0114885|               en|   Waiting to Exhale|\"Cheated on, mist...|       0.0| Glo and Robin ta...| determined to fi...|            3.859495|/16XOMpEaLWkrcPqS...|        0|      0|          1995-12-22|81452156|               127.0|[{'iso_639_1': 'e...|Released|         0.0|Waiting to Exhale|\n",
            "|false| {'id': 96871, 'na...|       0|[{'id': 35, 'name...|                NULL|11862|tt0113041|               en|Father of the Bri...|Just when George ...|  8.387519|/e64sOI48hQXyru7n...|[{'name': 'Sandol...|[{'iso_3166_1': '...|          1995-02-10| 76578911|    106|[{'iso_639_1': 'e...|Released|Just When His Wor...|Father of the Bri...|   False|         5.7|              173|\n",
            "+-----+---------------------+--------+--------------------+--------------------+-----+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+---------+-------+--------------------+--------+--------------------+--------------------+--------+------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Genre Data\n",
        "\n",
        "- **Objective**: Split the 'genres' column into an array when genres are stored as a string with separators.\n",
        "- **Operation**: Utilize the `split` function from PySpark's `sql.functions` to divide the genre string.\n",
        "- **Note**: The separator used here is `\"\\\\|\"`. Adjust this based on the actual delimiter in your data.\n"
      ],
      "metadata": {
        "id": "q_XAgMbY6BZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of splitting genres if it's a string with separators\n",
        "movies_df = movies_df.withColumn(\"genres_array\", split(col(\"genres\"), \"\\\\|\"))  # Adjust separator as per your data"
      ],
      "metadata": {
        "id": "hf6TXJh7As3m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Data Analysis Workflow\n",
        "\n",
        "- **Initialization of Spark Session**: If starting afresh, initialize the `SparkSession`. This is essential for leveraging Spark's capabilities.\n",
        "  \n",
        "- **Loading the Dataset**: Assuming the dataset hasn't been loaded yet, load it from a CSV file. This step involves specifying the path to your dataset and indicating that the first row contains headers.\n",
        "\n",
        "- **Data Cleaning and Parsing for Genres**:\n",
        "  - The genres column, formatted as a JSON string, needs parsing into a more usable format.\n",
        "  - Define a schema matching the structure of the genres data, focusing on the id and name.\n",
        "  - Convert this JSON-like string into an array of structs and then extract the genre names.\n",
        "\n",
        "- **Cleaning Numerical Columns**:\n",
        "  - Numerical columns like popularity, vote_average, and runtime might contain outliers or incorrect data.\n",
        "  - Cast these columns to appropriate data types and apply logical filters, e.g., ensuring `vote_average` is within a 0-10 range and `runtime` represents realistic values.\n",
        "\n",
        "- **Analyzing Distributions of Numerical Features**:\n",
        "  - Post-cleaning, analyze the distributions of numerical features such as popularity, vote_average, and runtime to understand the data better.\n",
        "\n",
        "- **Counting Movies per Genre**:\n",
        "  - With genres correctly parsed, count how many movies fall into each genre, providing insights into the dataset's genre distribution.\n"
      ],
      "metadata": {
        "id": "pTwo9ofl6Nh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, from_json, explode, split\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, FloatType, IntegerType\n",
        "\n",
        "# 1. Initialize Spark Session (Assuming this is a fresh start. If not, you can skip reinitializing SparkSession)\n",
        "spark = SparkSession.builder.appName(\"MovieDataAnalysis\").getOrCreate()\n",
        "\n",
        "# 2. Load the dataset (Assuming this is needed. If your DataFrame is already loaded and cleaned, skip this part)\n",
        "movies_path = \"movies_metadata.csv\"\n",
        "movies_df = spark.read.option(\"header\", \"true\").csv(movies_path)\n",
        "\n",
        "# 3. Data Cleaning and Parsing for genres\n",
        "\n",
        "# Define the schema of the genres column as it appears to be a JSON string\n",
        "schema = ArrayType(StructType([\n",
        "    StructField('id', StringType(), nullable=True),\n",
        "    StructField('name', StringType(), nullable=True)\n",
        "]))\n",
        "\n",
        "# Convert the JSON-like string in the genres column to an array of structs, then extract just the names\n",
        "movies_df = movies_df.withColumn(\"genres_parsed\", from_json(\"genres\", schema)) \\\n",
        "                     .withColumn(\"genre_names\", explode(col(\"genres_parsed.name\")))\n",
        "\n",
        "# 4. Cleaning numerical columns (popularity, vote_average, and runtime) to handle outliers or incorrect data\n",
        "# Assuming vote_average should be between 0 and 10, and runtime should be realistic (e.g., less than 500 minutes)\n",
        "\n",
        "movies_df = movies_df.withColumn(\"popularity\", col(\"popularity\").cast(FloatType())) \\\n",
        "                     .withColumn(\"vote_average\", col(\"vote_average\").cast(FloatType())) \\\n",
        "                     .withColumn(\"runtime\", col(\"runtime\").cast(IntegerType())) \\\n",
        "                     .filter((col(\"vote_average\") <= 10) & (col(\"runtime\") <= 500) & (col(\"runtime\") > 0))\n",
        "\n",
        "# 5. Analyze distributions of numerical features after cleaning\n",
        "movies_df.describe(['popularity', 'vote_average', 'runtime']).show()\n",
        "\n",
        "# 6. Count movies per genre with corrected genres data\n",
        "movies_df.groupBy(\"genre_names\").count().orderBy('count', ascending=False).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhKtOB8qfao_",
        "outputId": "b4551176-55dc-4a27-c7bd-ee5f6849524e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+\n",
            "|summary|        popularity|      vote_average|           runtime|\n",
            "+-------+------------------+------------------+------------------+\n",
            "|  count|             81341|             81350|             81350|\n",
            "|   mean|3.6963099428738646|5.7638647886845105| 99.19290719114936|\n",
            "| stddev| 7.528419560271575|1.6360319504336787|28.479781979992627|\n",
            "|    min|               0.0|               0.0|                 1|\n",
            "|    max|          547.4883|              10.0|               500|\n",
            "+-------+------------------+------------------+------------------+\n",
            "\n",
            "+---------------+-----+\n",
            "|    genre_names|count|\n",
            "+---------------+-----+\n",
            "|          Drama|18236|\n",
            "|         Comedy|11456|\n",
            "|       Thriller| 6991|\n",
            "|        Romance| 6092|\n",
            "|         Action| 5922|\n",
            "|         Horror| 4306|\n",
            "|          Crime| 3914|\n",
            "|    Documentary| 3338|\n",
            "|      Adventure| 3136|\n",
            "|Science Fiction| 2714|\n",
            "|         Family| 2451|\n",
            "|        Mystery| 2262|\n",
            "|        Fantasy| 2070|\n",
            "|      Animation| 1693|\n",
            "|        Foreign| 1431|\n",
            "|          Music| 1353|\n",
            "|        History| 1222|\n",
            "|            War| 1166|\n",
            "|        Western|  937|\n",
            "|       TV Movie|  660|\n",
            "+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IzWdsPpIfaWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genre and Language-based Movie Recommendation\n",
        "\n",
        "- **Objective**: Recommend movies based on a specified genre and language.\n",
        "- **Method**: Filter the DataFrame for movies that match both the genre and language criteria. Then, order the results by popularity to ensure the top recommendations are the most popular movies within the specified genre and language.\n",
        "- **Output**: Selects and displays the movie's title, overview, popularity score, and poster path for the top `num_movies` recommendations.\n",
        "- **Customization**: The number of movies to recommend (`num_movies`) can be adjusted as needed. By default, it recommends the top 10 movies.\n",
        "- **Note**: The `genre_names` and `original_language` fields are used for filtering. Ensure these columns are present and correctly formatted in your DataFrame.\n"
      ],
      "metadata": {
        "id": "p8kXNfBc6XnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(genre, language, num_movies=10):\n",
        "    return movies_df.filter((col(\"genre_names\") == genre) & (col(\"original_language\") == language))\\\n",
        "                    .orderBy(col(\"popularity\").desc())\\\n",
        "                    .select(\"title\", \"overview\", \"popularity\", \"poster_path\")\\\n",
        "                    .limit(num_movies)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gzCf-8uuBiTf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetching and Displaying Movie Recommendations\n",
        "\n",
        "- **Operation**: Executes the `recommend_movies` function to fetch the top 5 English comedy movies based on popularity.\n",
        "- **Parameters**: The genre is set to \"Comedy\", the language to \"en\" (English), and the number of movies to 5.\n",
        "- **Display**: The results are displayed with details including the movie title, overview, popularity score, and poster path. The `truncate=False` parameter ensures that the output shows the full text of each field without truncation.\n"
      ],
      "metadata": {
        "id": "v8CrXZJT6eZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_movies = recommend_movies(\"Comedy\", \"en\", 5)\n",
        "recommended_movies.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c116z0EgaBD",
        "outputId": "1b26ffb8-66f8-4951-fa9b-0f93157d9516"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+\n",
            "|title                                           |overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |popularity|poster_path                     |\n",
            "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+\n",
            "|Minions                                         |Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world.                                                                                                                                                                                                                                                                                                                   |547.4883  |/q0R4crx2SehcEEQEkYObktdeFy.jpg |\n",
            "|Big Hero 6                                      |The special bond that develops between plus-sized inflatable robot Baymax, and prodigy Hiro Hamada, who team up with a group of friends to form a band of high-tech heroes.                                                                                                                                                                                                                                                                                                         |213.84991 |/9gLu47Zw5ertuFTZaxXOvNfy78T.jpg|\n",
            "|Guardians of the Galaxy Vol. 2                  |The Guardians must fight to keep their newfound family together as they unravel the mysteries of Peter Quill's true parentage.                                                                                                                                                                                                                                                                                                                                                      |185.331   |/y4MBh0EjBlMuOzv9axM4qJlmhzz.jpg|\n",
            "|Pirates of the Caribbean: Dead Men Tell No Tales|Thrust into an all-new paycheck, a down-on-his-luck Capt. Jack Sparrow feels the winds of ill-fortune blowing even more strongly when deadly ghost sailors led by his old nemesis, the evil Capt. Salazar, escape from the Devil's Triangle. Jack's only hope of a payout lies in seeking out the legendary Trident of Numbers, but to find it, he must forge an uneasy alliance with a reasonably intelligent and pretty astronomer and a irritating young man in the British navy.|133.82782 |/xbpSDU3p7YUGlu9Mr6Egg2Vweto.jpg|\n",
            "|Captain Underpants: The First Epic Movie        |Two mischievous kids hypnotize their mean elementary school principal and turn him into their comic book creation, the kind-hearted and elastic-banded Captain Underpants.                                                                                                                                                                                                                                                                                                          |88.56124  |/AjHZIkzhPXrRNE4VSLVWx6dirK9.jpg|\n",
            "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+--------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifying Favorite Movie IDs in the Dataset\n",
        "\n",
        "- **Purpose**: To ascertain whether specific movies, identified by their IDs, are present within our dataset.\n",
        "- **Favorite Movie IDs**: A predefined list contains the IDs of interest, such as `[1, 100, 200]`. This list can be tailored to include the actual movie IDs you want to check.\n",
        "- **Execution**: The code filters the movie DataFrame, `movies_df`, for rows where the `id` matches any in the list of favorite movie IDs. It then selects and displays the `id` and `original_title` columns for these matches.\n",
        "- **Note**: This operation is crucial for validating that the movies of interest are indeed part of the dataset, especially before performing further analyses or recommendations based on these specific IDs.\n"
      ],
      "metadata": {
        "id": "dzcfQkbM6npn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a list of favorite movie IDs\n",
        "favorite_movie_ids = [1, 100, 200]  # Replace these IDs with the actual IDs you're interested in\n",
        "\n",
        "# Now, check if these movie IDs exist in your dataset\n",
        "movies_df.filter(col(\"id\").isin(favorite_movie_ids)).select(\"id\", \"original_title\").show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Nk4NpjfHHKAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdb9e48-2867-4377-9226-ff092e355284"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|      original_title|\n",
            "+---+--------------------+\n",
            "|100|Lock, Stock and T...|\n",
            "|100|Lock, Stock and T...|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genre Data Exploration and Transformation\n",
        "\n",
        "- **Objective**: The initial step involves displaying unique genres present in the dataset to ensure the genre names are correctly captured and to understand the diversity of the data.\n",
        "- **Display Unique Genres**: Selects the distinct genre names from the `genre_names` column of the `movies_df` DataFrame and displays them. This helps in verifying the genre data integrity.\n",
        "- **Exploding Genre Names** (Optional): In scenarios where further analysis requires one genre per row for each movie, the `explode` function is utilized. This operation transforms the `genre_names` array, creating a new row for each genre associated with a movie, thus facilitating row-wise genre analysis.\n",
        "- **Visualization**: Post-exploding, the DataFrame is displayed again to illustrate the new structure with individual genres per row, enhancing clarity on how data transformation impacts the DataFrame's layout.\n"
      ],
      "metadata": {
        "id": "uVeWWaC0629i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "# Display unique genres to verify the names, assuming the correct column name is 'genre_names'\n",
        "movies_df.select(\"genre_names\").distinct().show()\n",
        "# Explode the genre_names array to have one genre per row (optional)\n",
        "movies_df = movies_df.withColumn(\"genre\", explode(\"genre_names\"))\n",
        "movies_df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ouQOhxkPHToG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6453f1-911c-4e80-b94d-0eb96e07fd36"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|         genre_names|\n",
            "+--------------------+\n",
            "| [Thriller, Mystery]|\n",
            "|[Comedy, Horror, ...|\n",
            "|[Comedy, Adventur...|\n",
            "|[Crime, Comedy, T...|\n",
            "|[Action, War, Wes...|\n",
            "|[Drama, Romance, ...|\n",
            "|[Family, Adventur...|\n",
            "|[Mystery, Fantasy...|\n",
            "|[Science Fiction,...|\n",
            "|[Drama, Horror, A...|\n",
            "|[Action, Adventur...|\n",
            "|[Thriller, Comedy...|\n",
            "|[Horror, Mystery,...|\n",
            "|[Animation, Adven...|\n",
            "|[Drama, Thriller,...|\n",
            "|[Drama, Crime, My...|\n",
            "|[Drama, History, ...|\n",
            "|[Comedy, Drama, F...|\n",
            "|[Music, Drama, Co...|\n",
            "|[Western, Documen...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----+---------------------+--------+--------------------+--------------------+---+---------+-----------------+--------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+-------+---------+-----+------------+----------+--------------------+--------------------+--------------------+---------+\n",
            "|adult|belongs_to_collection|  budget|              genres|            homepage| id|  imdb_id|original_language|original_title|            overview|popularity|         poster_path|production_companies|production_countries|release_date|  revenue|runtime|    spoken_languages|  status|tagline|    title|video|vote_average|vote_count|       genres_parsed|         genre_names|       parsed_genres|    genre|\n",
            "+-----+---------------------+--------+--------------------+--------------------+---+---------+-----------------+--------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+-------+---------+-----+------------+----------+--------------------+--------------------+--------------------+---------+\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Family|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|Animation|\n",
            "|False| {'id': 10194, 'na...|30000000|[{'id': 16, 'name...|http://toystory.d...|862|tt0114709|               en|     Toy Story|Led by Woody, And...| 21.946943|/rhIRbceoE9lR4veE...|[{'name': 'Pixar ...|[{'iso_3166_1': '...|  1995-10-30|373554033|     81|[{'iso_639_1': 'e...|Released|   NULL|Toy Story|False|         7.7|      5415|[{16, Animation},...|[Animation, Comed...|[{16, Animation},...|   Comedy|\n",
            "+-----+---------------------+--------+--------------------+--------------------+---+---------+-----------------+--------------+--------------------+----------+--------------------+--------------------+--------------------+------------+---------+-------+--------------------+--------+-------+---------+-----+------------+----------+--------------------+--------------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Popularity-Based Movie Recommendations\n",
        "\n",
        "- **Goal**: To recommend a specified number of movies based on their popularity, ensuring each recommended movie is unique.\n",
        "- **Distinct Selection**: Initially, duplicates are removed based on the movie ID to ensure each movie is only considered once for recommendations. This is crucial for obtaining a diverse set of recommendations.\n",
        "- **Ordering**: Movies are then ordered by their popularity in descending order. This step prioritizes movies that have garnered more attention or higher popularity scores.\n",
        "- **Limiting Recommendations**: The list of recommendations is limited to the top `num_recommendations` movies, allowing for control over how many movies are suggested. By default, 10 movies are recommended.\n",
        "- **Output**: The function returns the top recommended movies, showcasing their ID, original title, and popularity score.\n",
        "\n"
      ],
      "metadata": {
        "id": "-9Ua0QjB7DXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies_by_popularity(num_recommendations=10):\n",
        "    # Attempt to get distinct movies based on ID before ordering by popularity\n",
        "    # Note: This approach might not perfectly preserve the order of popularity due to the distinct operation\n",
        "    popular_movies_recommendations = movies_df.dropDuplicates([\"id\"]) \\\n",
        "                                               .orderBy(col(\"popularity\").desc()) \\\n",
        "                                               .select(\"id\", \"original_title\", \"popularity\") \\\n",
        "                                               .limit(num_recommendations)\n",
        "    return popular_movies_recommendations\n",
        "\n",
        "# Example usage: Get top 10 most popular distinct movies\n",
        "top_popular_movies = recommend_movies_by_popularity()\n",
        "top_popular_movies.show()\n"
      ],
      "metadata": {
        "id": "6wvnFbKuIAo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8730aace-7dd0-4619-d29d-b379a123c230"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+----------+\n",
            "|    id|      original_title|popularity|\n",
            "+------+--------------------+----------+\n",
            "|211672|             Minions|  547.4883|\n",
            "|297762|        Wonder Woman| 294.33704|\n",
            "|321612|Beauty and the Beast| 287.25366|\n",
            "|339403|         Baby Driver| 228.03275|\n",
            "|177572|          Big Hero 6| 213.84991|\n",
            "|283995|Guardians of the ...|   185.331|\n",
            "| 19995|              Avatar| 185.07089|\n",
            "|245891|           John Wick| 183.87038|\n",
            "|210577|           Gone Girl| 154.80101|\n",
            "|131631|The Hunger Games:...|   147.098|\n",
            "+------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preparing the Ratings Dataset\n",
        "\n",
        "- **Initial Setup**: It's presupposed that the Spark session, `spark`, is already active, establishing the foundational setup for data processing.\n",
        "- **Data Source**: The path to the ratings dataset, `ratings.csv`, should be specified accurately to ensure successful loading. The variable `ratings_path` holds this file path.\n",
        "- **Reading the Data**: Utilizing Spark's `read.csv` method, the ratings dataset is loaded into a DataFrame, `ratings_df`. This step includes specifying `header=True` to use the first row for column names and `inferSchema=True` to automatically deduce the data types.\n",
        "- **Schema Adjustment**: Although schema inference attempts to correctly identify data types, explicit casting ensures the `userId`, `movieId`, and `rating` columns are of integer and float types, respectively. This precision is pivotal for subsequent data handling and analysis, particularly in contexts requiring specific data type constraints, such as model training.\n",
        "\n"
      ],
      "metadata": {
        "id": "asuZHytD7PUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming SparkSession `spark` is already initialized\n",
        "ratings_path = \"ratings.csv\"  # Update this to your actual file path\n",
        "ratings_df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
        "\n",
        "# Assuming your ratings CSV has columns: userId, movieId, and rating\n",
        "# Optionally, cast columns to appropriate types if not automatically inferred correctly\n",
        "ratings_df = ratings_df.select(\n",
        "    col(\"userId\").cast(\"integer\"),\n",
        "    col(\"movieId\").cast(\"integer\"),\n",
        "    col(\"rating\").cast(\"float\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "HA9lcx-dkQmx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Schema Specification and Data Import for Movie Ratings\n",
        "\n",
        "- **Schema Definition**: A schema is explicitly defined to ensure each column in the `ratings.csv` file is correctly typed. This schema includes:\n",
        "  - `userId` as an integer\n",
        "  - `movieId` as an integer\n",
        "  - `rating` as a float\n",
        "  - `timestamp` as an integer, noted as optional depending on the use case.\n",
        "- **Loading Data with Schema**: The `spark.read.csv` method is used to load the `ratings.csv` file into a DataFrame, `ratings_df`, applying the predefined schema. This approach provides control over data types from the outset, crucial for data consistency and avoiding errors in downstream processes.\n",
        "- **Initial Data View**: Displaying the first few rows with `.show(5)` gives a quick glimpse into the dataset, verifying the load operation's success and the schema's application.\n",
        "\n",
        "This methodical setup ensures the ratings data is accurately represented in Spark, facilitating reliable analyses or model training that depend on this data.\n"
      ],
      "metadata": {
        "id": "99Mpezmi7XeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType, FloatType, StructType, StructField\n",
        "\n",
        "# Define schema for ratings.csv if needed\n",
        "ratings_schema = StructType([\n",
        "    StructField(\"userId\", IntegerType(), True),\n",
        "    StructField(\"movieId\", IntegerType(), True),\n",
        "    StructField(\"rating\", FloatType(), True),\n",
        "    StructField(\"timestamp\", IntegerType(), True)  # Optional, can be omitted if not using\n",
        "])\n",
        "\n",
        "# Load the ratings data\n",
        "ratings_df = spark.read.csv(\"ratings.csv\", header=True, schema=ratings_schema)\n",
        "ratings_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGuDx5a-kYJN",
        "outputId": "a7f48363-6112-4550-d9b0-6724b2cac3ec"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     1|    110|   1.0|1425941529|\n",
            "|     1|    147|   4.5|1425942435|\n",
            "|     1|    858|   5.0|1425941523|\n",
            "|     1|   1221|   5.0|1425941546|\n",
            "|     1|   1246|   5.0|1425941556|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering with ALS for Movie Recommendations\n",
        "\n",
        "- **Data Preparation**: The `ratings_df` DataFrame, derived from `ratings.csv`, is split into training (80%) and testing (20%) sets to facilitate model evaluation. This split ensures the model can be trained on a majority of the data while retaining a portion for unbiased evaluation.\n",
        "- **Model Initialization**: The Alternating Least Squares (ALS) algorithm is initialized with specific parameters tailored to the recommendation context. These include specifying `userId`, `movieId`, and `rating` columns, along with strategies for handling cold start and non-negativity constraints.\n",
        "- **Model Training**: The ALS model is trained on the training set, learning latent factors that predict user preferences for movies based on the provided ratings.\n",
        "- **Model Evaluation**: Post-training, the model's performance is evaluated on the test set by calculating the Root Mean Square Error (RMSE) between predicted and actual ratings. This metric provides insight into the model's accuracy.\n",
        "- **Generating Recommendations**: Finally, the trained model is used to generate movie recommendations. This includes generating top movie recommendations for all users and showcasing a specific example for a user with `userId = 100`.\n",
        "\n"
      ],
      "metadata": {
        "id": "RmAuXd7u7xpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Assuming ratings_df is your DataFrame from ratings.csv\n",
        "(train, test) = ratings_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\", nonnegative=True, implicitPrefs=False)\n",
        "\n",
        "model = als.fit(train)\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))\n",
        "\n",
        "# Make recommendations for all users\n",
        "userRecs = model.recommendForAllUsers(5)\n",
        "# For a specific user (e.g., userId = 100)\n",
        "userRecs.where(userRecs.userId == 100).select(\"recommendations.movieId\", \"recommendations.rating\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FogBlF69k_lx",
        "outputId": "4e6c6dfa-3193-451a-d244-3e916be0c351"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 0.830190081176456\n",
            "+--------------------------------------+------------------------------------------------------+\n",
            "|movieId                               |rating                                                |\n",
            "+--------------------------------------+------------------------------------------------------+\n",
            "|[126219, 155671, 105952, 27911, 72159]|[5.9294863, 4.075789, 3.9352481, 3.8017979, 3.7471368]|\n",
            "+--------------------------------------+------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning ALS Model Parameters\n",
        "\n",
        "- **Model Configuration**: Begins with the configuration of the ALS (Alternating Least Squares) model for collaborative filtering. This step involves setting parameters such as `userCol`, `itemCol`, and `ratingCol` to specify the DataFrame columns representing users, items (movies), and ratings, respectively. The `coldStartStrategy` is set to 'drop' to handle new users or movies without ratings, and `nonnegative` ensures that the algorithm predicts non-negative rating values.\n",
        "- **Parameter Grid Construction**: To enhance the model's performance, a parameter grid is defined using `ParamGridBuilder`. This grid specifies multiple values for key ALS parameters—`rank`, `maxIter`, and `regParam`—allowing for systematic exploration of various combinations during model tuning.\n",
        "    - `rank`: Represents the number of latent factors (dimensions) in the model. Higher values can capture more nuances but may lead to overfitting.\n",
        "    - `maxIter`: Determines the maximum number of iterations the ALS algorithm will perform. More iterations can lead to a more refined model at the cost of increased computation time.\n",
        "    - `regParam`: The regularization parameter helps prevent overfitting by penalizing larger model coefficients. Tuning this parameter is crucial for balancing model complexity with predictive performance.\n",
        "- **Grid Summary**: The constructed parameter grid encompasses combinations of these parameters, setting the stage for cross-validation or other model selection techniques to identify the optimal model configuration.\n"
      ],
      "metadata": {
        "id": "uTBolWt177wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True)\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(als.rank, [5, 10, 15]) \\\n",
        "    .addGrid(als.maxIter, [10, 20]) \\\n",
        "    .addGrid(als.regParam, [0.01, 0.1]) \\\n",
        "    .build()\n",
        "\n"
      ],
      "metadata": {
        "id": "S-eohjB5lfOH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing ALS Model via Cross-Validation\n",
        "\n",
        "- **Model Evaluation Setup**: Initializes the `RegressionEvaluator` with RMSE (Root Mean Square Error) as the metric. This evaluator assesses the ALS model's accuracy by comparing predicted ratings against actual ratings, aiming to minimize RMSE for better prediction accuracy.\n",
        "- **Cross-Validator Configuration**: Configures the `CrossValidator` process with several key components:\n",
        "    - `estimator`: Specifies the ALS model as the estimator whose parameters need optimization.\n",
        "    - `estimatorParamMaps`: Incorporates the parameter grid defined previously, detailing different configurations of ALS parameters (`rank`, `maxIter`, and `regParam`) to be tested.\n",
        "    - `evaluator`: Utilizes the RMSE-based evaluator to gauge model performance across different parameter configurations.\n",
        "    - `numFolds`: Sets the number of folds for cross-validation to 3, meaning the dataset is divided into three parts, with each part serving as the test set once and the training set twice. Increasing the number of folds enhances the validation process at the cost of additional computation.\n",
        "- **Model Training and Selection**: Executes the cross-validation process by fitting the training dataset. This step involves training and evaluating the model across all combinations of parameters specified in `paramGrid` for each fold. The best-performing model configuration, i.e., the one with the lowest average RMSE across folds, is automatically selected.\n",
        "- **Resulting Model**: The output, `cvModel`, represents the ALS model tuned with the optimal set of parameters as determined by cross-validation. This model is expected to provide a balance between predictive accuracy and generalization capability on unseen data.\n"
      ],
      "metadata": {
        "id": "ghUkB5kb8Fn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "crossval = CrossValidator(estimator=als,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)  # Use 3+ folds in practice\n",
        "\n",
        "# Fit the model\n",
        "cvModel = crossval.fit(train)\n",
        "\n"
      ],
      "metadata": {
        "id": "iZaR-QwzpCcA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Optimized ALS Model\n",
        "\n",
        "- **Best Model Extraction**: Retrieves the best-performing model from the cross-validation process. This model, `bestModel`, is the one with the optimal parameter configuration that resulted in the lowest RMSE during the tuning phase.\n",
        "- **Prediction on Test Data**: Utilizes `bestModel` to transform the test dataset, generating predictions for each rating. This step applies the model to data it hasn't seen during training or validation, providing insight into how well the model generalizes to new information.\n",
        "- **Model Performance Assessment**: The `RegressionEvaluator` is again employed to calculate the RMSE between the predicted ratings and the actual ratings in the test set. This metric quantifies the model's prediction accuracy on unseen data.\n",
        "- **Performance Output**: Displays the Root Mean Square Error (RMSE) of the optimized model when applied to the test dataset. A lower RMSE value indicates better predictive accuracy, reflecting the effectiveness of the model tuning and selection process.\n"
      ],
      "metadata": {
        "id": "uB-jYN_c8RIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestModel = cvModel.bestModel  # or tvsModel.bestModel for TrainValidationSplit\n",
        "predictions = bestModel.transform(test)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw0sGDijpI5p",
        "outputId": "699e191d-ccc2-484b-a48e-6741cdae9842"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 0.8183209816719098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Optimized Model and Concluding Remarks\n",
        "\n",
        "- **Model Selection**: After completing the cross-validation process, the best-performing model configuration is identified and extracted as `bestModel`. This model represents the optimal parameter set within the tested grid, aiming to strike the best balance between complexity and predictive accuracy.\n",
        "- **Performance Evaluation**: The `bestModel` is then applied to the unseen test dataset to evaluate its final performance. This step is crucial for assessing how well the model generalizes to new data, which is a key indicator of its practical utility.\n",
        "- **RMSE Computation**: Utilizes the `RegressionEvaluator` with RMSE as the metric to calculate the error rate of the optimized model's predictions on the test set. A lower RMSE value indicates higher prediction accuracy, reflecting the model's effectiveness in capturing user preferences.\n",
        "- **Output Display**: The final RMSE value is displayed, offering a quantitative measure of the model's prediction error. This metric provides valuable insight into the model's performance and serves as a benchmark for future model improvements or comparisons.\n",
        "- **Conclusion**: Successfully tuning and evaluating an ALS model for collaborative filtering demonstrates the power of machine learning in enhancing recommendation systems. The process of parameter tuning, model selection, and performance evaluation is integral to developing robust, accurate recommendation engines. Continuous iteration and refinement, based on new data or advanced techniques, can further improve model performance, catering to evolving user preferences and behaviors.\n"
      ],
      "metadata": {
        "id": "usj_esPo9Nsa"
      }
    }
  ]
}